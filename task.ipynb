{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "\n",
    "from collections import defaultdict, namedtuple\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "\n",
    "sys.path.append(\"../dl/models/research/\")\n",
    "sys.path.append(\"../dl/models/research/object_detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import label_map_util\n",
    "from utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What model to download.\n",
    "MODEL_NAME = 'ssd_mobilenet_v1_coco_11_06_2017'\n",
    "MODEL_FILE = MODEL_NAME + '.tar.gz'\n",
    "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
    "\n",
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb'\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = os.path.join('../dl/models/research/object_detection/data', 'mscoco_label_map.pbtxt')\n",
    "\n",
    "NUM_CLASSES = 90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#opener = urllib.request.URLopener()\n",
    "#opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
    "tar_file = tarfile.open(MODEL_FILE)\n",
    "\n",
    "for file in tar_file.getmembers():\n",
    "    file_name = os.path.basename(file.name)\n",
    "    if \"frozen_inference_graph.pb\" in file_name:\n",
    "        tar_file.extract(file, os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a (frozen) Tensorflow model into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_CKPT, \"rb\") as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading label map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(image):\n",
    "    (im_width, im_height) = image.size\n",
    "    return np.array(image.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH_TO_TEST_IMAGES_DIR = \"../dl/VOCdevkit/VOC2012/JPEGImages\"\n",
    "PATH_TO_IMAGE_SETS = \"../dl/VOCdevkit/VOC2012/ImageSets/Main/\"\n",
    "\n",
    "train = []\n",
    "with open(os.path.join(PATH_TO_IMAGE_SETS, \"train.txt\")) as file:\n",
    "    train = file.read().splitlines()\n",
    "    \n",
    "validate = []\n",
    "with open(os.path.join(PATH_TO_IMAGE_SETS, \"val.txt\")) as file:\n",
    "    validate = file.read().splitlines()\n",
    "    \n",
    "TRAIN_IMAGE_PATHS = [os.path.join(PATH_TO_TEST_IMAGES_DIR, \"{}.jpg\".format(image)) for image in train]\n",
    "VALIDATE_IMAGE_PATHS = [os.path.join(PATH_TO_TEST_IMAGES_DIR, \"{}.jpg\".format(image)) for image in validate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (12, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DetectionResult = namedtuple(\"DetectionResult\", \"boxes scores classes\")\n",
    "\n",
    "def detect_objects(files, annotations, visualize=True, metric=None):\n",
    "    metric_values = []\n",
    "    \n",
    "    with detection_graph.as_default():\n",
    "        with tf.Session(graph=detection_graph) as sess:\n",
    "            # Definite input and output Tensors for detection_graph\n",
    "            image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "            # Each box represents a part of the image where a particular object was detected.\n",
    "            detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "\n",
    "            # Each score represent how level of confidence for each of the objects.\n",
    "            # Score is shown on the result image, together with the class label.\n",
    "            detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "            detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "            num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "\n",
    "            for (image_path, annotation) in zip(files, annotations):\n",
    "                image = Image.open(image_path)\n",
    "\n",
    "                # the array based representation of the image will be used later in order to prepare the\n",
    "                # result image with boxes and labels on it.\n",
    "                image_np = load_image_into_numpy_array(image)\n",
    "\n",
    "                # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "                image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "\n",
    "                # Actual detection.\n",
    "                (boxes, scores, classes, num) = sess.run(\n",
    "                    [detection_boxes, detection_scores, detection_classes, num_detections],\n",
    "                    feed_dict={image_tensor: image_np_expanded})\n",
    "                \n",
    "                if metric:\n",
    "                    result = DetectionResult(boxes.squeeze(), scores.squeeze(), classes.squeeze())\n",
    "                    metric_values.append(metric(annotation, result))\n",
    "                \n",
    "                # Visualization of the results of a detection.\n",
    "                if visualize:\n",
    "                    vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                        image_np,\n",
    "                        np.squeeze(boxes),\n",
    "                        np.squeeze(classes).astype(np.int32),\n",
    "                        np.squeeze(scores),\n",
    "                        category_index,\n",
    "                        use_normalized_coordinates=True, line_thickness=8)\n",
    "\n",
    "                    plt.figure(figsize=IMAGE_SIZE)\n",
    "                    plt.imshow(image_np)\n",
    "    \n",
    "    return metric_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "PATH_TO_IMAGE_ANNOTATIONS = \"../dl/VOCdevkit/VOC2012/Annotations\"\n",
    "VALIDATE_IMAGE_ANNOTATIONS = [ET.parse(os.path.join(PATH_TO_IMAGE_ANNOTATIONS, \"{}.xml\".format(image))).getroot() for image in validate]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BoundingBox = namedtuple(\"BoundingBox\", \"xmin ymin xmax ymax\")\n",
    "Object = namedtuple(\"Object\", \"name bndbox\")\n",
    "\n",
    "def get_bndbox(node):\n",
    "    args = {child.tag: child.text for child in node}\n",
    "    return BoundingBox(float(args[\"xmin\"]), float(args[\"ymin\"]), float(args[\"xmax\"]), float(args[\"ymax\"]))\n",
    "    \n",
    "def get_object(node):\n",
    "    args = {child.tag: child for child in node}\n",
    "    return Object(args[\"name\"].text, get_bndbox(args[\"bndbox\"]))\n",
    "    \n",
    "def get_objects(node):\n",
    "    return [get_object(child) for child in node if child.tag == \"object\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_id = {category[\"name\"]: category[\"id\"] for category in categories}\n",
    "\n",
    "def is_valid(annotation):\n",
    "    objects = get_objects(annotation)\n",
    "    names = np.unique(list(map(lambda it: it.name, objects)))\n",
    "    \n",
    "    # no objects\n",
    "    if len(names) == 0:\n",
    "        return False\n",
    "    \n",
    "    # objects on the image are not unique!\n",
    "    if len(objects) != len(names):\n",
    "        return False\n",
    "    \n",
    "    # all labels are correct\n",
    "    return all((name in category_id for name in names))\n",
    "    \n",
    "images, annotations = [], []\n",
    "\n",
    "for (image, annotation) in zip(VALIDATE_IMAGE_PATHS, VALIDATE_IMAGE_ANNOTATIONS):\n",
    "    if is_valid(annotation):\n",
    "        images.append(image)\n",
    "        annotations.append(annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_objects(images[:3], annotations[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_detected_acc(obj, result):\n",
    "    indices = (result.classes == category_id[obj.name])\n",
    "    return np.max(result.scores[indices]) > 0.5 if np.sum(indices) else 0\n",
    "\n",
    "def accuracy(annotation, result):\n",
    "    objects = get_objects(annotation)\n",
    "    return np.mean([is_detected_acc(obj, result) for obj in objects])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = detect_objects(images, annotations, visualize=False, metric=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: {:.2f}%\".format(100 * np.mean(values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_intersection(box_1, box_2):\n",
    "    xmin = max(box_1.xmin, box_2.xmin)\n",
    "    ymin = max(box_1.ymin, box_2.ymin)\n",
    "    xmax = min(box_1.xmax, box_2.xmax)\n",
    "    ymax = min(box_1.ymax, box_2.ymax)\n",
    "    \n",
    "    return (xmax - xmin) * (ymax - ymin)\n",
    "\n",
    "def get_square(box):\n",
    "    return (box.xmax - box.xmin) * (box.ymax - box.ymin)\n",
    "\n",
    "def get_iou(box_1, box_2):\n",
    "    intersection = get_intersection(box_1, box_2)\n",
    "    union = get_square(box_1) + get_square(box_2) - intersection \n",
    "    return intersection / union\n",
    "\n",
    "def build_bdnbox(args):\n",
    "    return BoundingBox(375.0 * float(args[0]), 500.0 * float(args[1]), 375 * float(args[2]), 500 * float(args[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_max_iou(obj, result):\n",
    "    indices = (result.classes == category_id[obj.name])\n",
    "    boxes = (build_bdnbox(box) for box in result.boxes[indices])\n",
    "    return max(0, np.max([get_iou(box, obj.bndbox) for box in boxes]) if np.sum(indices) else 0)\n",
    "    \n",
    "def IoU(annotation, result):\n",
    "    objects = get_objects(annotation)\n",
    "    return np.mean([get_max_iou(obj, result) for obj in objects])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = detect_objects(images, annotations, visualize=False, metric=IoU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average IoU: {:.2f} px^2\".format(np.mean(values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_detected_map(obj, result):\n",
    "    indices = (result.classes == category_id[obj.name])\n",
    "    boxes = (build_bdnbox(box) for box in result.boxes[indices])\n",
    "    \n",
    "    for box in boxes:\n",
    "        if get_iou(box, obj.bndbox) > 0.5:\n",
    "            return 1\n",
    "        \n",
    "    return 0\n",
    "    \n",
    "def MAP(annotation, result):\n",
    "    objects = get_objects(annotation)\n",
    "    return np.mean([is_detected_map(obj, result) for obj in objects])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = detect_objects(images, annotations, visualize=False, metric=MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MAP: {:.2f}%\".format(100 * np.mean(values)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
